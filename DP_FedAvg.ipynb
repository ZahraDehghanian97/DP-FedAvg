{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOh9NVKUCBNbdGslyURxY2G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahraDehghanian97/DP-FedAvg/blob/master/DP_FedAvg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FedAvg"
      ],
      "metadata": {
        "id": "eKJpyCrWPqMv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "simulate a distributed learning scenario with multiple clients and a central server."
      ],
      "metadata": {
        "id": "CQKfPAsmPDgz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMqOGSd3O7c8",
        "outputId": "9aa3df01-6269-425c-ef54-83d99145aad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 60656547.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Partition the dataset across clients\n",
        "num_clients = 4\n",
        "client_indices = [list(range(i * len(trainset) // num_clients, (i + 1) * len(trainset) // num_clients)) for i in range(num_clients)]\n",
        "\n",
        "# Create DataLoaders for each client\n",
        "client_loaders = [DataLoader(trainset, batch_size=64, sampler=SubsetRandomSampler(indices)) for indices in client_indices]\n",
        "\n",
        "# Create a DataLoader for the test dataset\n",
        "test_loader = DataLoader(testset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "implement FedAvg"
      ],
      "metadata": {
        "id": "xojWuDT4PJhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "def train_client(client_loader, global_model, local_epochs=1):\n",
        "    local_model = SimpleCNN()\n",
        "    local_model.load_state_dict(global_model.state_dict())\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(local_model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    for epoch in range(local_epochs):\n",
        "        for i, data in enumerate(client_loader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = local_model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return local_model.state_dict()\n",
        "\n",
        "def aggregate_models(global_model, client_models, client_loaders):\n",
        "    total_samples = sum([len(loader.dataset) for loader in client_loaders])\n",
        "    avg_state_dict = global_model.state_dict()\n",
        "\n",
        "    for key in avg_state_dict.keys():\n",
        "        avg_state_dict[key] = torch.stack([client_models[i][key] * len(client_loaders[i].dataset) / total_samples for i in range(len(client_models))], dim=0).sum(dim=0)\n",
        "\n",
        "    global_model.load_state_dict(avg_state_dict)\n",
        "    return global_model\n",
        "\n",
        "def test_model(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "uBf5zUKtPSZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train model on fixed number of rounds"
      ],
      "metadata": {
        "id": "d8dYlCzjPXkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_model = SimpleCNN()\n",
        "num_rounds = 30\n",
        "local_epochs = 1\n",
        "\n",
        "for round in range(num_rounds):\n",
        "    client_models = [train_client(client_loader, global_model, local_epochs) for client_loader in client_loaders]\n",
        "    global_model = aggregate_models(global_model, client_models, client_loaders)\n",
        "    accuracy = test_model(global_model, test_loader)\n",
        "    print(f\"Round {round + 1}: Global model accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaj_IBMRPXJt",
        "outputId": "6d68df18-2766-4e33-ba5f-09028847ae4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1: Global model accuracy: 0.0989\n",
            "Round 2: Global model accuracy: 0.1020\n",
            "Round 3: Global model accuracy: 0.1068\n",
            "Round 4: Global model accuracy: 0.1701\n",
            "Round 5: Global model accuracy: 0.1943\n",
            "Round 6: Global model accuracy: 0.1806\n",
            "Round 7: Global model accuracy: 0.1974\n",
            "Round 8: Global model accuracy: 0.2339\n",
            "Round 9: Global model accuracy: 0.2772\n",
            "Round 10: Global model accuracy: 0.3047\n",
            "Round 11: Global model accuracy: 0.3284\n",
            "Round 12: Global model accuracy: 0.3430\n",
            "Round 13: Global model accuracy: 0.3626\n",
            "Round 14: Global model accuracy: 0.3837\n",
            "Round 15: Global model accuracy: 0.4012\n",
            "Round 16: Global model accuracy: 0.4102\n",
            "Round 17: Global model accuracy: 0.4211\n",
            "Round 18: Global model accuracy: 0.4261\n",
            "Round 19: Global model accuracy: 0.4365\n",
            "Round 20: Global model accuracy: 0.4434\n",
            "Round 21: Global model accuracy: 0.4493\n",
            "Round 22: Global model accuracy: 0.4546\n",
            "Round 23: Global model accuracy: 0.4603\n",
            "Round 24: Global model accuracy: 0.4682\n",
            "Round 25: Global model accuracy: 0.4729\n",
            "Round 26: Global model accuracy: 0.4796\n",
            "Round 27: Global model accuracy: 0.4842\n",
            "Round 28: Global model accuracy: 0.4931\n",
            "Round 29: Global model accuracy: 0.4933\n",
            "Round 30: Global model accuracy: 0.5015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DP-FedAvg"
      ],
      "metadata": {
        "id": "JAxjAeUXPmuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.distributions.laplace import Laplace\n",
        "\n",
        "def train_client_dp(client_loader, global_model, local_epochs,delta,epsilon):\n",
        "    local_model = SimpleCNN()\n",
        "    local_model.load_state_dict(global_model.state_dict())\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(local_model.parameters(), lr=0.001, momentum=0.9)\n",
        "    for epoch in range(local_epochs):\n",
        "        for i, data in enumerate(client_loader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = local_model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        # Add Laplace noise to the client model\n",
        "        for param in local_model.parameters():\n",
        "            noise = Laplace(0, 2 * len(client_loader.dataset) * delta /(100 *epsilon))\n",
        "            param.data.add_(noise.sample())\n",
        "\n",
        "    return local_model.state_dict()\n"
      ],
      "metadata": {
        "id": "uitDpDuppqbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def aggregate_models_dp(global_model, client_models, client_loaders,delta,epsilon):\n",
        "    # Aggregate the client models with differential privacy\n",
        "    total_samples = sum([len(loader.dataset) for loader in client_loaders])\n",
        "    avg_state_dict = global_model.state_dict()\n",
        "    for key in avg_state_dict.keys():\n",
        "        noise = Laplace(0, 2 * delta / epsilon)\n",
        "        noise_term = noise.sample(avg_state_dict[key].shape)\n",
        "        avg_state_dict[key] = torch.stack([client_models[i][key] * len(client_loaders[i].dataset) / total_samples for i in range(len(client_models))], dim=0).sum(dim=0) + noise_term\n",
        "    global_model.load_state_dict(avg_state_dict)\n",
        "\n",
        "    return global_model\n"
      ],
      "metadata": {
        "id": "_NxYe32giVs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_model_dp = SimpleCNN()\n",
        "num_rounds = 30\n",
        "local_epochs = 1\n",
        "epsilon = 1.0\n",
        "delta = 1e-5\n",
        "\n",
        "for round in range(num_rounds):\n",
        "    client_models = [train_client_dp(client_loader, global_model_dp, local_epochs,delta,epsilon) for client_loader in client_loaders]\n",
        "    global_model_dp = aggregate_models_dp(global_model_dp, client_models, client_loaders,delta,epsilon)\n",
        "    accuracy = test_model(global_model_dp, test_loader)\n",
        "    print(f\"Round {round + 1}: Global (DP-FedAvg) model dp accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnDlk0vEiyH3",
        "outputId": "9e25499b-3599-4dfd-dd69-6be0d0f82a90"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1: Global (DP-FedAvg) model dp accuracy: 0.1000\n",
            "Round 2: Global (DP-FedAvg) model dp accuracy: 0.1000\n",
            "Round 3: Global (DP-FedAvg) model dp accuracy: 0.1000\n",
            "Round 4: Global (DP-FedAvg) model dp accuracy: 0.1057\n",
            "Round 5: Global (DP-FedAvg) model dp accuracy: 0.0760\n",
            "Round 6: Global (DP-FedAvg) model dp accuracy: 0.0973\n",
            "Round 7: Global (DP-FedAvg) model dp accuracy: 0.0998\n",
            "Round 8: Global (DP-FedAvg) model dp accuracy: 0.1461\n",
            "Round 9: Global (DP-FedAvg) model dp accuracy: 0.0999\n",
            "Round 10: Global (DP-FedAvg) model dp accuracy: 0.1016\n",
            "Round 11: Global (DP-FedAvg) model dp accuracy: 0.1000\n",
            "Round 12: Global (DP-FedAvg) model dp accuracy: 0.1000\n",
            "Round 13: Global (DP-FedAvg) model dp accuracy: 0.1000\n",
            "Round 14: Global (DP-FedAvg) model dp accuracy: 0.1000\n",
            "Round 15: Global (DP-FedAvg) model dp accuracy: 0.1067\n",
            "Round 16: Global (DP-FedAvg) model dp accuracy: 0.1000\n",
            "Round 17: Global (DP-FedAvg) model dp accuracy: 0.1000\n",
            "Round 18: Global (DP-FedAvg) model dp accuracy: 0.1000\n",
            "Round 19: Global (DP-FedAvg) model dp accuracy: 0.1251\n",
            "Round 20: Global (DP-FedAvg) model dp accuracy: 0.1243\n",
            "Round 21: Global (DP-FedAvg) model dp accuracy: 0.1230\n",
            "Round 22: Global (DP-FedAvg) model dp accuracy: 0.0997\n",
            "Round 23: Global (DP-FedAvg) model dp accuracy: 0.1245\n",
            "Round 24: Global (DP-FedAvg) model dp accuracy: 0.1256\n",
            "Round 25: Global (DP-FedAvg) model dp accuracy: 0.1088\n",
            "Round 26: Global (DP-FedAvg) model dp accuracy: 0.1102\n",
            "Round 27: Global (DP-FedAvg) model dp accuracy: 0.1286\n",
            "Round 28: Global (DP-FedAvg) model dp accuracy: 0.1294\n",
            "Round 29: Global (DP-FedAvg) model dp accuracy: 0.1306\n",
            "Round 30: Global (DP-FedAvg) model dp accuracy: 0.1510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To evaluate the trade-off between privacy and utility, we can vary the privacy parameter (ϵ) in DP-FedAvg and plot the accuracy-privacy trade-off curve."
      ],
      "metadata": {
        "id": "g95YeaHNtEyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Define the range of privacy parameter values to test\n",
        "epsilons = np.logspace(-4, 2, 10)\n",
        "num_rounds = 20\n",
        "local_epochs = 1\n",
        "delta = 1e-5\n",
        "\n",
        "# Evaluate the model accuracy for each epsilon value\n",
        "accuracies = []\n",
        "for epsilon in epsilons:\n",
        "  global_model_dp = SimpleCNN()\n",
        "  for round in range(num_rounds):\n",
        "    client_models = [train_client_dp(client_loader, global_model_dp, local_epochs,delta,epsilon) for client_loader in client_loaders]\n",
        "    global_model_dp = aggregate_models_dp(global_model_dp, client_models, client_loaders,delta,epsilon)\n",
        "  accuracy = test_model(global_model_dp, test_loader)\n",
        "  print(f\"Epsilon {epsilon}: Global (DP-FedAvg) model dp accuracy: {accuracy:.4f}\")\n",
        "  accuracies.append(accuracy)\n",
        "\n",
        "# Plot the accuracy-privacy trade-off curve\n",
        "plt.semilogx(epsilons, accuracies)\n",
        "plt.xlabel('Privacy parameter (epsilon)')\n",
        "plt.ylabel('Model accuracy')\n",
        "plt.title('Accuracy-privacy trade-off curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zY6GOdjqtKbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tune parameter and train model on same number of rounds "
      ],
      "metadata": {
        "id": "Q1OY2KbjP9zU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trade-off between privacy and model accuracy can be discussed by analyzing the accuracy-privacy trade-off curve. Generally, we observe that as the level of privacy protection increases (as ϵ decreases), the model accuracy decreases. This is due to the added noise that is necessary to achieve differential privacy, which reduces the accuracy of the model. However, the rate of accuracy decrease varies depending on the dataset, model, and privacy parameters, and there may be a sweet spot where the privacy protection is high enough to satisfy the privacy requirements while the model accuracy is still acceptable.\n",
        "\n"
      ],
      "metadata": {
        "id": "9iQRqn6Dvm2I"
      }
    }
  ]
}